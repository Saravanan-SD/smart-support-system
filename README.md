# **Smart Support System**  
_AI-powered ticket triage with LLMs, background jobs, and a scalable backend._

---

## **ğŸš€ What It Does**

- Accepts **support tickets** from users  
- **Classifies** them with an **LLM** (Category + Priority)  
- **Summarizes** the text for agents  
- **Detects PII** (emails & phone numbers)  
- **Stores lifecycle** in MongoDB  
- **Runs everything asynchronously** for speed & scalability  

---

## **ğŸ§© How It Works**

1. **User submits a ticket** â†’ `/api/classify`  
2. **FastAPI** puts the job in **Redis** (no waiting!)  
3. **Celery workers** process tasks in **two stages**:
   - **Classification Queue** â†’ Quick AI triage  
   - **Enrichment Queue** â†’ Summarization + PII detection  
4. **MongoDB** stores the ticket from **â€œreceivedâ€ â†’ â€œcompletedâ€**  
5. **Flower Dashboard** shows live job progress and retries  

---

## **âš¡ Why Itâ€™s Cool**

- **Instant API response** â†’ Background jobs handle heavy LLM work  
- **Multi-queue Celery** â†’ Scales like a real production system  
- **Retries + Monitoring** â†’ No lost tasks, no silent failures  
- **Event-driven pipeline** â†’ Perfect example of **eventual consistency** in system design  

---

## **ğŸ›  Tech Stack**

- **FastAPI** â€“ Async API server  
- **Groq LLM + LangChain** â€“ Ticket classification brain  
- **Celery + Redis** â€“ Background job engine  
- **MongoDB** â€“ Persistent ticket storage  
- **Flower** â€“ Real-time queue monitoring  

---

## **ğŸ¯ Quick Start**

```bash
# 1. Start dependencies
docker run -d -p 6379:6379 redis
docker run -d -p 27017:27017 mongo

# 2. Run FastAPI
uvicorn app.main:app --reload

# 3. Start workers
celery -A worker worker --loglevel=info --pool=solo -Q classification
celery -A worker worker --loglevel=info --pool=solo -Q enrichment

